###############################################################################
######################## Discovery and identification #########################
###############################################################################

# A dataset should have a concise title. Follow the same approach like in
# giving titles to journal articles.
# Attribute: mandatory
# Input type: free text
title: 'insert_title'

# A dataset should have a descriptive summary allowing users to understand
# better what the dataset is about and for what it can be used for.
# Attribute: mandatory
# Input type: free text
summary: 'insert_summary'

# Dataset keywords are similar like journal paper keywords. They highlight
# particularities of the given dataset. Ideally keywords should be sourced
# from control vocabularies which are used by communities.
# Keywords should be provided as a list.
# Attribute: mandatory
# Input type: free text or terms from controlled vocabulary
keywords: ['insert_keyword_1','insert_keyword_2']


# If some or all keywords are sourced from controlled vocabularies it is a good
# practice to provide a list of the controlled vocabulary URI's from where the
# keywords are sourced from. One example is taxonomy of wind energy topics:
# 'http://data.windenergy.dtu.dk/taxonomy/'
# Attribute: recommended
# Input type: fixed resolvable URIs
keywords_vocabulary: ['insert_vocab_URI_1','insert_vocab_URI_2']

# To identify dataset you need to provide a unique & persistent identifier(PID).
# The most obvious candidate for dataset PID is DOI.
# A way to obtain it prior publishing your dataset is to make a DOI reservation.
# Then simply insert the reserved DOI here.
# PIDs should be resolvable.
# Attribute: mandatory
# Input type: fixed resolvable PID
dataset_id: 'insert_PID'

# An URI of the authority body that generated dataset_id
# Attribute: recommended
# Input type: fixed resolvable URI
dataset_id_authority: 'insert_authority_body_URL'

# If dataset is a part of larger data collection is_part_of provides the
# link to the collection. For example, data collection will have PID, such as
# DOI. Therefore, is_part_of will contain that PID.
# Attribute: recommended
# Input type: fixed resolvable PID
is_part_of: 'insert_data_collection_PID'

# If the entire dataset is split to multiple files into multiple files
# is_related_to holds ids of remaining files which make dataset complete.
# The ids of remaining files could be simple as file names.
# Attribute: mandatory (if dataset is split to multiple files)
# Input type: fixed resolvable PIDs
is_related_to: ['insert_id_file_1', 'insert_id_file_2']

# Dataset is generated wither using virtual (models) or physical(instruments)
# infrastructures. Accordingly, it is always a good practice to indicate
# what infrastructure was used to generate the dataset.
# infrastructure_id should contain a list of ids of the used infrastructures.
# The ids could be for example URLs to the instruments.
# Attribute: optional
# Input type: free text or fixed resolvable URIs/PIDs
infrastructure_id: ['insert_infrastructure_id_1', 'insert_infrastructure_id_2']


# A location, thus site, where data was created.
# Attribute: mandatory (only for measurements datasets)
# Input type: free text
site: 'insert_site_name'

# Provide a list of people who take a part in data creation.
# List them according to the priority as FirstName LastName.
# Attribute: mandatory
# Input type: free text
creator_name: ['FirstName_1 LastName_1', 'FirstName_2 LastName_2']

# Provide a list of emails of data creators. The list elements must follow
# the order of creators' names.
# Attribute: mandatory
# Input type: free text
creator_email: ['creator_1_email', 'creator_2_email']

# Since people to tend to change their positions or jobs email addresses tend
# to be obsolete. To maintain a possibility of contacts a much more persistent
# approach is to provide ORCiD ids of creators.
# Attribute: recommended
# Input type: fixed resolvable PID
creator_id: ['creator_1_ORCiD', 'creator_2_ORCID']

# List of creator names don't tell us much about who done what in the process
# of data creation. creator_role provides a means to highlight a particular
# role(s) each data creator had. The roles could be described using CredIT
# taxonomy:
# https://like-itn-digitalization.readthedocs.io/en/latest/1_research_lifecycle/#roles-in-lifecycle
# Attribute: optional
# Input type: free text or terms from controlled vocabulary
creator_role: ['creator_1_main_role', 'creator_2_main_role']


# Provide a list of people who contributed to data creation, but where not
# sufficient contributors to be seen as data creators.
# List them according to the priority as FirstName LastName.
# Attribute: recommended
# Input type: free text
contributor_name: ['FirstName_1 LastName_1', 'FirstName_2 LastName_2']

# Same as creator_email
# Attribute: recommended
# Input type: free text
contributor_email: ['contributor_1_email', 'contributor_2_email']

# Same as creator_id
# Attribute: recommended
# Input type: fixed resolvable PIDs
contributor_id: ['contributor_1_ORCiD', 'contributor_2_ORCID']

# Same as creator_role
# Attribute: optional
# Input type: free text or terms from controlled vocabulary
contributor_role: ['contributor_1_main_role', 'contributor_2_main_role']

# Provide a list of projects which provided funding for the dataset generation.
# Attribute: recommended
# Input type: free text
project_name: ['project_name_1', 'project_name_2']

# Provide a list of projects numbers, typically identifiable by OpenAIER.
# The list must be ordered according to project_name.
# Attribute: recommended
# Input type: free text
project_number: ['project_number_1', 'project_number_1']

# In case when the project(s) has a landing page provide them.
# The list must be ordered according to project_name.
# Attribute: recommended
# Input type: fixed resolvable URI
project_url: ['project_1_home_page', 'project_2_home_page']

# Provide the source of funding for projects.
# The list must be ordered according to project_name.
# Attribute: recommended
# Input type: free text
project_funder: ['project_1_funder', 'project_2_funder']


# It is important to help users understand in what state data are. This is
# explicitly stated in data_mode. The data_mode takes terms from controlled
# vocabulary ["Raw", "Provisional", "Delayed-mode", "Mixed"] where:
# - Raw represents unprocessed data
#
# - Provisional data means that some calibrations or editing on data may
#   have been done, but the data is not thought to be fully processed.
#   Refer to the history attribute for more detailed information.
#
# - Delayed-mode data represents data published after all calibrations and
#   quality control procedures have been applied on the internally recorded or
#   best available original data. This is the best possible version of
#   processed data.
#
# - Mixed data indicates that the dataset contains data in more than
#   one of the above states.
#
# Attribute: mandatory
# Input type: term from controlled vocabulary
data_mode : 'insert_data_mode'

###############################################################################
########################### Publication information ###########################
###############################################################################

license: # licence that specifies usage and distribution of dataset
distribution_statement: # notation that marks dataset according to its security classification to ensure it is circulated only among the authorized recipients.
                        # Potentially the distribution statement could look like this:
                        # Statement A : Approved for public release; distribution is unlimited.
                        # Statement B : Approved for public release; distribution is defined by license.
                        # Statement C : Distribution authorized to (insert authorized entities) only; (fill in reason); (date of determination). Other requests for this document shall be referred to (insert controlling government office).
                        # Statement D : Distribution authorized to (insert authorized entities) and their contractors; (fill in reason); (date of determination). Other requests for this document shall be referred to (insert controlling government office).

publisher_name: # The data publisher's name.
                # The publisher may be an individual or an institution.
publisher_email: # The data publisher's email.
                 # The publisher may be an individual or an institution.
publisher_url: # The data publisher's url.
               # The publisher may be an individual or an institution.
citation: # The citation to be used in publications using the dataset.
update_interval : # in case if dataset is periodically updated (i.e., if this is dynamic dataset) otherwise leave it empty



###############################################################################
############################### Used conventions ##############################
###############################################################################

format_version: # data format version (could be for example "marinet2 NetCDF 2.1" or a resolvable URI)
metadata_schema: # indicates schema used to format/describe metadata, ideally it should be a resolvable URI
conventions: # all conventions used for naming of variables and dimensions, could be a list of resolvable URIs provided as a list


###############################################################################
########################## Spatio-temporal information ########################
###############################################################################

# top level description
feature_type: # Description of the spatio-temporal shape of the data held in the netCDF using a vocabulary specified in CF 1.6.
cdm_data_type: # The Unidata CDM (common data model) data type used by THREDDS. e.g. point, profile, section, station, station_profile, trajectory, grid, radial, swath, image; use Grid for gridded HFR data. Recommended.

# spatial coverage information
reference_system: # Either specify coordinate system in a form of "EPSG:epsg_code" or write "CUSTOM"
coordinate_mapping: # specifies how relative x, y and z coordinates are mapped to absolute one, if reference_system: "CUSTOM" then coordinate_mapping can be dropped
  - name: "x"
    value: # insert to what abs coordinate it is mapped, if reference_system: "EPSG:4326"
           # value will be set to "longitude"
  - name: "y"
    value: # insert to what abs coordinate it is mapped, if reference_system: "EPSG:4326"
           # value will be set to "latitude"
  - name: "z"
    value: # it can be either 'height' or 'depth'

spatial_x_min: # insert min x
spatial_x_max: # insert max x
spatial_x_units: # insert units for x
spatial_x_resolution: # insert resolution for x (optional)

spatial_y_min: # insert min y
spatial_y_max: # insert may y
spatial_y_units: # insert units for y
spatial_y_resolution: # insert resolution for y (optional)

spatial_z_min: # insert min z
spatial_z_max: # insert maz z
spatial_z_units: # insert units for z
spatial_z_resolution: # insert resolution for z (optional)

# temporal coverage information
time_coverage_start: # Start date of the data in UTC. Time must be specified as a string according to the ISO8601 standard: "YYYY-MM-DDThh:mm:ssZ”.
time_coverage_end: # Final date of the data in UTC. Time must be specified as a string according to the ISO8601 standard: "YYYY-MM-DDThh:mm:ssZ”.
time_coverage_resolution: #Interval between records. ISO8601 standard must be used: PnYnMnDTnHnMnS.
time_coverage_duration: #Duration of the time coverage of the data. ISO8601 standard must be used: PnYnMnDTnHnMnS.

###############################################################################
############################### Data provenance ###############################
###############################################################################

date_create: # The date on which the data file was created.
              # Version date and time for the data contained in the file. (UTC).
              # Time must be specified as a string according to the ISO8601 standard: "YYYY-MM- DDThh:mm:ssZ”.
date_update: # Timestamp specifying when the contents (i.e. its attributes and/or values)
             # of the file were last changed Time must be specified as a string according to the ISO8601 standard: "YYYY-MM-DDThh:mm:ssZ”
history: # Provides an audit trail for modifications to the original data.
         # It should contain a separate line for each modification, with each line beginning with a timestamp, and including user name,
         # modification name, and modification arguments. The time stamp must be specified as a string according to the ISO8601 standard: "YYYY-MM-DDThh:mm:ssZ”.

processing_level: # Level of processing and quality control applied to data. This probably cannot be generic and it will depend on the community.
                  # For example in case of lidars these levels are:
                  # LEVEL 0: Backscatter signal
                  # LEVEL 1A: Individual Doppler spectra
                  # LEVEL 1B: QC (i.e. filtered) Individual Doppler spectra
                  # LEVEL 1C: QC Averaged Doppler spectra
                  # LEVEL 2A: Estimated non-averaged radial velocity
                  # LEVEL 2B: Estimated non-averaged QC radial velocity
                  # LEVEL 2C: Estimated averaged QC radial velocity
                  # LEVEL 3: Reconstructed wind
                  # LEVEL 4: Extracted flow related parameters (e.g., wind turbine wake width)
